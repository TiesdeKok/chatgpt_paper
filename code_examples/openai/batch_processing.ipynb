{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0677690b-bc59-41b1-bf6c-1340b5f6e4a8",
   "metadata": {},
   "source": [
    "# OpenAI - fast batch processing\n",
    "\n",
    "The guide is a companion to the paper *\"Generative LLMs and Textual Analysis in Accounting:(Chat)GPT as Research Assistant?\"* ([SSRN](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4429658))\n",
    "\n",
    "**Author:** [Ties de Kok](https://www.tiesdekok.com)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799fdde1-c830-4edd-a062-56592955a0cf",
   "metadata": {},
   "source": [
    "----\n",
    "# Imports\n",
    "----\n",
    "\n",
    "\n",
    "All the dependencies required for this notebook are provided in the `environment.yml` file.\n",
    "\n",
    "To install: `conda env create -f environment.yml` --> this creates the `gllm` environment.\n",
    "\n",
    "I recommend using Python 3.9 or higher to avoid dependency conflicts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1969ecc-dd72-475a-ae51-79bdc83c84d7",
   "metadata": {},
   "source": [
    "**Python built-in libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ec5462-905d-4b7c-b748-a43dbbe84b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, copy, random, json, time, datetime\n",
    "from pathlib import Path\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae5855-5a12-4098-9545-495fbc540506",
   "metadata": {},
   "source": [
    "**Libraries for interacting with the OpenAI API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c77af21a-0a1c-4610-a213-a4565742bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import openai\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccebae9d-fd4c-42da-81ea-7b4672bbec07",
   "metadata": {},
   "source": [
    "**General helper libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c877637b-27c2-4d17-934d-a1e0c65422fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca152ca-0c4c-4820-bc51-a443ee10dbae",
   "metadata": {},
   "source": [
    "### Import custom async logic\n",
    "\n",
    "This is a custom implementation I created based on the async example code by OpenAI. This code maximizes the token throughput using async requests to the OpenAI API. \n",
    "\n",
    "**Warning!** This function is experimental and might break, use at your own risk and discretion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46259ca4-2d06-49ed-a759-bc2d396a9e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fast_openai_async\n",
    "make_batch_predictions = fast_openai_async.make_batch_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95257da-1df7-44de-8cc9-49071d6db842",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0ccdeb1-e3f2-4f96-b924-9a36287e78ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0b98b8-afcd-40b6-a2cb-173f95a14e98",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da331675-1d54-41a2-9c04-c77d331c3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function makes it easier to print rendered markdown through a code cell.\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def mprint(text, *args, **kwargs):\n",
    "    if 'end' in kwargs.keys():\n",
    "        text += kwargs['end']\n",
    "        \n",
    "    display(Markdown(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52592dcd-1e6e-4740-b6bd-aa8765d58c66",
   "metadata": {
    "tags": []
   },
   "source": [
    "-----\n",
    "# Toy example\n",
    "----\n",
    "\n",
    "I will solve the exact same problem as the \"zero_shot.ipynb\" file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c2b8c-b553-44f6-9443-344c1a508941",
   "metadata": {},
   "source": [
    "## Create prompt dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7afbc4-fd74-4559-bd99-6c2711e0a657",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fa46d21-8c65-4af1-9381-fd4025af1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path.cwd() / \"data\" / \"statements.json\", \"r\", encoding = \"utf-8\") as f:\n",
    "    statement_list = json.load(f)\n",
    "\n",
    "statement_df = pd.DataFrame(statement_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b549282c-1393-45a1-b76e-a08fc48abc91",
   "metadata": {},
   "source": [
    "#### Define prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30c4c8a7-3155-4c3d-ac7f-9cd4f8148891",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Task: classify whether the statement below contains a forward looking statements (fls).\n",
    "Rules:\n",
    "- Answer using JSON in the following format: {{\"contains_fls\" : 0 or 1}}\n",
    "Statement:\n",
    "> {statement}\n",
    "JSON =\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f51abb2-3cd9-48fa-b8d5-df216c2d67a9",
   "metadata": {},
   "source": [
    "#### Create dataset to make predictions for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcee2d43-9c87-476e-9a1c-fa4a85c4a78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_list = []\n",
    "for i, row in statement_df.iterrows():\n",
    "    prompt = prompt_template.format(**{\n",
    "                \"statement\" : row[\"statement\"]\n",
    "            })\n",
    "    \n",
    "    prompt_list.append({\n",
    "        \"id\" : row[\"i\"], ## This is important to merge the results back.\n",
    "        \"prompt\" : prompt\n",
    "    })\n",
    "len(prompt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4073e301-db12-4ff3-9911-57cbce6cc792",
   "metadata": {},
   "source": [
    "## Generate predictions\n",
    "\n",
    "**Important note:** the rate limits are hard-coded values in the `fast_openai_async.py` file and you might need to update them to reflect the rate limits shown on your OpenAI account page:\n",
    "\n",
    "https://platform.openai.com/account/rate-limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "125284b3-48ee-4123-b9b4-493134e482d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting request #0\n",
      "INFO:root:Starting request #10\n",
      "INFO:root:Starting request #20\n",
      "INFO:root:Starting request #30\n",
      "INFO:root:Starting request #40\n",
      "INFO:root:Starting request #50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time is: 2023-10-04 16:49:42.001683\n",
      "Running with the following rate limits: 3,395 RPM and 79,200 TPM\n",
      "Submitting 60 jobs for gpt-3.5-turbo!\n",
      "Results are saved to the following file: C:/Users/kokti/Dropbox/Work/Research/chatgpt_paper/github/chatgpt_paper/code_examples/openai/data/results_20231004164942_demo_run_v1.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Parallel processing complete. Results saved to C:/Users/kokti/Dropbox/Work/Research/chatgpt_paper/github/chatgpt_paper/code_examples/openai/data/results_20231004164942_demo_run_v1.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, the results are available in the following file:\n",
      "C:/Users/kokti/Dropbox/Work/Research/chatgpt_paper/github/chatgpt_paper/code_examples/openai/data/results_20231004164942_demo_run_v1.jsonl\n",
      "End time is: 2023-10-04 16:49:43.473135\n"
     ]
    }
   ],
   "source": [
    "RUN = True\n",
    "if RUN:\n",
    "    print(\"Start time is:\", datetime.datetime.now())\n",
    "    _ = await make_batch_predictions(\n",
    "        prompt_list,\n",
    "        \"gpt-3.5-turbo\", # e.g., \"gpt-4\", \"gpt-3.5-turbo-0613\", etc\n",
    "        Path.cwd() / \"data\",\n",
    "        Path.cwd() / \"data\",\n",
    "        max_tokens = 600,\n",
    "        #system_message = system_message, ## Not specifying it sets it to default\n",
    "        return_json = False,\n",
    "        print_interval = 10,\n",
    "        label = f\"demo_run_v1\",\n",
    "        prompt_template = prompt_template,\n",
    "        store_prompt_loc = Path.cwd() / \"data\"\n",
    "    )\n",
    "    print(\"End time is:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510d1fb-b4b2-4ede-99da-bb6180ffd5a5",
   "metadata": {},
   "source": [
    "## Process results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f5a53b-10b7-419d-8012-c18cc4148693",
   "metadata": {},
   "source": [
    "#### Load in results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c98201cd-ed6e-40e1-8a61-a21f520ff836",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_file = \"C:/Users/kokti/Dropbox/Work/Research/chatgpt_paper/github/chatgpt_paper/code_examples/openai/data/results_20231004164533_demo_run_v1.jsonl\"\n",
    "\n",
    "success_res, error_res = fast_openai_async.proc_results(res_file, \"chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5284438-feb3-4d00-aa7b-7c0374f8f401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'contains_fls': 1, 'id': 2},\n",
       " {'contains_fls': 1, 'id': 12},\n",
       " {'contains_fls': 0, 'id': 13}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_res[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eccb97-c6c5-4049-b6cf-bf247854ce70",
   "metadata": {},
   "source": [
    "#### Inspect tokens used\n",
    "\n",
    "**Important note:** these calculations are done using hard-coded values in the `fast_openai_async.py` file and are only up-to-date as per September 2023. \n",
    "You might need to update them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b8a584e-cdd4-4793-8b02-ca5664933329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost estimates:\n",
      "\n",
      "- gpt-4 - $0.17\n",
      "- gpt-35-4k - $0.01\n",
      "- gpt-35-16k - $0.02\n",
      "- gpt-35-ft - $0.06\n",
      "\n",
      "Total number of tokens used: 5,141\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>qanda_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>76.683333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>85.683333</td>\n",
       "      <td>30.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.855402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.855402</td>\n",
       "      <td>17.464249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>15.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>30.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>45.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prompt_tokens  completion_tokens  total_tokens   qanda_id\n",
       "count      60.000000               60.0     60.000000  60.000000\n",
       "mean       76.683333                9.0     85.683333  30.500000\n",
       "std         3.855402                0.0      3.855402  17.464249\n",
       "min        68.000000                9.0     77.000000   1.000000\n",
       "25%        74.000000                9.0     83.000000  15.750000\n",
       "50%        77.000000                9.0     86.000000  30.500000\n",
       "75%        79.000000                9.0     88.000000  45.250000\n",
       "max        88.000000                9.0     97.000000  60.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Request 47 failed with Exception \n"
     ]
    }
   ],
   "source": [
    "fast_openai_async.calc_tokens_used(res_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b99ee9a-46dc-4ae9-b524-96336490e59b",
   "metadata": {},
   "source": [
    "#### Add results back to Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c84ae4f-e99f-4761-82d5-383617138ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(success_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba758907-b518-496e-999d-494d761289a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = res_df.rename(columns = {\n",
    "    \"id\" : \"i\",\n",
    "    \"contains_fls\" : \"fls_prediction\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0a97cb9-47b6-4d17-8611-f4b865943b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df = pd.merge(statement_df, res_df, on = \"i\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c923afed-8265-4902-b711-2e99cd1f6342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>statement</th>\n",
       "      <th>contains_fls</th>\n",
       "      <th>fls_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>In the last quarter, we managed to increase ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>We anticipate that our investments in R&amp;D will...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Our recent acquisition of XYZ Company has alre...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>We expect to see continued growth in the Asian...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>In the past year, we have successfully reduced...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Looking ahead, we're projecting a 5% increase ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>The launch of our latest software solution las...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>We believe the introduction of our new AI-powe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Our strong performance this year can be attrib...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>By expanding our sales team, we are confident ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    i                                          statement  contains_fls  \\\n",
       "0   1  In the last quarter, we managed to increase ou...             0   \n",
       "1   2  We anticipate that our investments in R&D will...             1   \n",
       "2   3  Our recent acquisition of XYZ Company has alre...             0   \n",
       "3   4  We expect to see continued growth in the Asian...             1   \n",
       "4   5  In the past year, we have successfully reduced...             0   \n",
       "5   6  Looking ahead, we're projecting a 5% increase ...             1   \n",
       "6   7  The launch of our latest software solution las...             0   \n",
       "7   8  We believe the introduction of our new AI-powe...             1   \n",
       "8   9  Our strong performance this year can be attrib...             0   \n",
       "9  10  By expanding our sales team, we are confident ...             1   \n",
       "\n",
       "   fls_prediction  \n",
       "0               0  \n",
       "1               1  \n",
       "2               0  \n",
       "3               1  \n",
       "4               0  \n",
       "5               1  \n",
       "6               0  \n",
       "7               1  \n",
       "8               0  \n",
       "9               1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a39c96-dbb3-49f8-a210-069e9dd624ed",
   "metadata": {},
   "source": [
    "#### Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0fcd682-f21a-4766-90fd-631399de67b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6357ef1e-703a-4ad5-9fd0-3b28b7d16b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        30\n",
      "           1       1.00      0.97      0.98        30\n",
      "\n",
      "    accuracy                           0.98        60\n",
      "   macro avg       0.98      0.98      0.98        60\n",
      "weighted avg       0.98      0.98      0.98        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "    combo_df[\"contains_fls\"], \n",
    "    combo_df[\"fls_prediction\"]\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
