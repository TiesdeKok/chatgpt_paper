{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0677690b-bc59-41b1-bf6c-1340b5f6e4a8",
   "metadata": {},
   "source": [
    "# Replicate + Llama2 - zero shot example\n",
    "\n",
    "The guide is a companion to the paper *\"Generative LLMs and Textual Analysis in Accounting:(Chat)GPT as Research Assistant?\"* ([SSRN](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4429658))\n",
    "\n",
    "**Author:** [Ties de Kok](https://www.tiesdekok.com)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799fdde1-c830-4edd-a062-56592955a0cf",
   "metadata": {},
   "source": [
    "----\n",
    "# Imports\n",
    "----\n",
    "\n",
    "\n",
    "All the dependencies required for this notebook are provided in the `environment.yml` file.\n",
    "\n",
    "To install: `conda env create -f environment.yml` --> this creates the `gllm` environment.\n",
    "\n",
    "I recommend using Python 3.9 or higher to avoid dependency conflicts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1969ecc-dd72-475a-ae51-79bdc83c84d7",
   "metadata": {},
   "source": [
    "**Python built-in libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ec5462-905d-4b7c-b748-a43dbbe84b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, copy, random, json, time, datetime\n",
    "from pathlib import Path\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae5855-5a12-4098-9545-495fbc540506",
   "metadata": {},
   "source": [
    "**Libraries for interacting with the OpenAI API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c77af21a-0a1c-4610-a213-a4565742bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccebae9d-fd4c-42da-81ea-7b4672bbec07",
   "metadata": {},
   "source": [
    "**General helper libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c877637b-27c2-4d17-934d-a1e0c65422fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95257da-1df7-44de-8cc9-49071d6db842",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ccdeb1-e3f2-4f96-b924-9a36287e78ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0b98b8-afcd-40b6-a2cb-173f95a14e98",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da331675-1d54-41a2-9c04-c77d331c3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function makes it easier to print rendered markdown through a code cell.\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def mprint(text, *args, **kwargs):\n",
    "    if 'end' in kwargs.keys():\n",
    "        text += kwargs['end']\n",
    "        \n",
    "    display(Markdown(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52592dcd-1e6e-4740-b6bd-aa8765d58c66",
   "metadata": {
    "tags": []
   },
   "source": [
    "-----\n",
    "# Toy example\n",
    "----\n",
    "\n",
    "I will use a hypothetical dataset of earnings call sentences and try to identify sentences with a forward-looking statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c2b8c-b553-44f6-9443-344c1a508941",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fa46d21-8c65-4af1-9381-fd4025af1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path.cwd() / \"data\" / \"statements.json\", \"r\", encoding = \"utf-8\") as f:\n",
    "    statement_list = json.load(f)\n",
    "\n",
    "statement_df = pd.DataFrame(statement_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e367301a-2e1f-41cb-95cb-6af74f95db2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the last quarter, we managed to increase our revenue by 15% due to the successful launch of our new product line.\n"
     ]
    }
   ],
   "source": [
    "sentence_1 = statement_df.iloc[0].statement\n",
    "print(sentence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6db9fee6-0c06-4f9f-a7f2-d55089c250ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We anticipate that our investments in R&D will lead to a 20% improvement in efficiency in the next two years.\n"
     ]
    }
   ],
   "source": [
    "sentence_2 = statement_df.iloc[1].statement\n",
    "print(sentence_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0562b95b-96fc-4f15-91e5-5768a4d0c6f6",
   "metadata": {},
   "source": [
    "----\n",
    "## Prompt engineering\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64655d5-f2f1-4af7-a252-7f5ea05fa1b1",
   "metadata": {},
   "source": [
    "### Define prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30c4c8a7-3155-4c3d-ac7f-9cd4f8148891",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Task: classify whether the statement below contains a forward looking statements (fls).\n",
    "Rules:\n",
    "- Answer using JSON in the following format: {{\"contains_fls\" : 0 or 1}}\n",
    "Statement:\n",
    "> {statement}\n",
    "JSON =\n",
    "\"\"\".strip()\n",
    "\n",
    "## Note, the curly braces are what we will fill in for each observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c19a4ee-b97b-446e-942e-f13d27334e5e",
   "metadata": {},
   "source": [
    "### Create prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cbe27a0-b166-47b7-a7e3-350f3a7bbc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(**{\n",
    "    \"statement\" : sentence_1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d36ae831-9f69-4c4a-8733-abf2c5cb4b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: classify whether the statement below contains a forward looking statements (fls).\n",
      "Rules:\n",
      "- Answer using JSON in the following format: {\"contains_fls\" : 0 or 1}\n",
      "Statement:\n",
      "> In the last quarter, we managed to increase our revenue by 15% due to the successful launch of our new product line.\n",
      "JSON =\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa6682f-faa4-4b4c-9b39-bcb383aede60",
   "metadata": {},
   "source": [
    "---\n",
    "## Set up replicate\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eb919b-a6e8-4faf-b7d3-196817a97750",
   "metadata": {},
   "source": [
    "In order to run the code below you need to install the replicate Python package:\n",
    "\n",
    "```\n",
    "## In your terminal / command line:\n",
    "pip install replicate\n",
    "\n",
    "## Or inside a Jupyter cell:\n",
    "!pip install replicate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30b7dcee-6280-45d6-bb78-a6599213b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b60c5fef-cc7c-4eaf-9e94-5ddaf999a27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your API key:  ········\n"
     ]
    }
   ],
   "source": [
    "if 'REPLICATE_API_TOKEN' not in os.environ:\n",
    "    os.environ['REPLICATE_API_TOKEN'] = getpass.getpass(prompt='Enter your API key: ')\n",
    "    \n",
    "replicate_key = os.environ['REPLICATE_API_TOKEN']\n",
    "    \n",
    "## KEEP YOUR KEY SECURE, ANYONE WITH ACCESS TO IT CAN GENERATE COSTS ON YOUR ACCOUNT!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9555d649-aaa3-4eff-9ab5-5a390571c76f",
   "metadata": {},
   "source": [
    "### Provide a demo generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e01239f-b621-4667-890d-9cc3494dbd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = replicate.run(\n",
    "    \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    input={\"prompt\": \"Tell me a funny joke about accountants\"},\n",
    "    stream = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9910f031-d301-4343-a2e0-b75bd1522ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure, here's a joke for you:\n",
      "\n",
      "Why did the accountant quit his job?\n",
      "\n",
      "Because he wanted to take his career to the next level!\n",
      "\n",
      "(Get it? \"Next level\" is a phrase often used in business and finance to describe growth or advancement, but in this case, it's a play on words because \"level\" can also refer to a floor or step in a building, implying that the accountant wants to leave his current job and move up to a better one.)\n",
      "\n",
      "I hope that brought a smile to your face! Is there anything"
     ]
    }
   ],
   "source": [
    "for item in output:\n",
    "    print(item, end = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a0d0b8-25b5-47e3-a394-0dee9a015202",
   "metadata": {},
   "source": [
    "### Make generation based on our prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07e61c56-3cb9-4f74-a9fd-dfbc8a3fc9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = replicate.run(\n",
    "    \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    input={\n",
    "        \"prompt\": prompt, \n",
    "        \"stop_sequences\" : \"}\",\n",
    "        \"temperature\" : 0.01 ## The replicate API currently has a bug where it doesn't accept 0. \n",
    "    },\n",
    ")\n",
    "\n",
    "res = \"\".join(list(output))\n",
    "\n",
    "res = (res + \"}\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b3248154-0fbd-4c1a-ac16-7620005898c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains_fls': 0}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84aaeb3-fe75-467e-9610-50ef94cacab8",
   "metadata": {},
   "source": [
    "### Wrap into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa518689-bfcc-493a-9e32-89fe15866c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(prompt):\n",
    "    output = replicate.run(\n",
    "        \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "        input={\n",
    "            \"prompt\": prompt, \n",
    "            \"stop_sequences\" : \"}\",\n",
    "            \"temperature\" : 0.01\n",
    "        },\n",
    "    )\n",
    "\n",
    "    res = \"\".join(list(output))\n",
    "\n",
    "    res = (res + \"}\").strip()\n",
    "    \n",
    "    json_res = json.loads(res)\n",
    "    \n",
    "    return json_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348758c3-70f4-4d12-9bbd-7164eac4b027",
   "metadata": {},
   "source": [
    "#### Apply to all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eaa58c74-a349-4669-a1ba-4d3ddcf1ccd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Item:** `0`\n",
       "> In the last quarter, we managed to increase our revenue by 15% due to the successful launch of our new product line.    \n",
       "\n",
       "*Prediction - contains FLS:* `0`\n",
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Item:** `1`\n",
       "> We anticipate that our investments in R&D will lead to a 20% improvement in efficiency in the next two years.    \n",
       "\n",
       "*Prediction - contains FLS:* `1`\n",
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Item:** `2`\n",
       "> Our recent acquisition of XYZ Company has already started to show positive results in terms of cost savings and market reach.    \n",
       "\n",
       "*Prediction - contains FLS:* `0`\n",
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Item:** `3`\n",
       "> We expect to see continued growth in the Asian market, with a potential increase in revenue of 25% over the next three years.    \n",
       "\n",
       "*Prediction - contains FLS:* `1`\n",
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Item:** `4`\n",
       "> In the past year, we have successfully reduced our operational costs by 10% through process improvements and better supply chain management.    \n",
       "\n",
       "*Prediction - contains FLS:* `0`\n",
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, row in statement_df.head().iterrows():\n",
    "    prompt = prompt_template.format(**{\n",
    "        \"statement\" : row[\"statement\"]\n",
    "    })\n",
    "    \n",
    "    prediction = make_prediction(prompt) \n",
    "    mprint(f\"\"\"\n",
    "**Item:** `{i}`\n",
    "> {row[\"statement\"]}    \n",
    "\n",
    "*Prediction - contains FLS:* `{prediction[\"contains_fls\"]}`\n",
    "<br><br>\n",
    "\"\"\".strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
