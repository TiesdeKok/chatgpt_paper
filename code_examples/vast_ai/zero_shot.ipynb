{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0677690b-bc59-41b1-bf6c-1340b5f6e4a8",
   "metadata": {},
   "source": [
    "# LlaMa2 + Vast.ai- zero shot example\n",
    "\n",
    "The guide is a companion to the paper *\"Generative LLMs and Textual Analysis in Accounting:(Chat)GPT as Research Assistant?\"* ([SSRN](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4429658))\n",
    "\n",
    "**Author:** [Ties de Kok](https://www.tiesdekok.com)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799fdde1-c830-4edd-a062-56592955a0cf",
   "metadata": {},
   "source": [
    "----\n",
    "# Imports\n",
    "----\n",
    "\n",
    "**Important:** please read the instructions in the `readme.md` file to set up a Vast.AI instance with the appropriate setup and packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1969ecc-dd72-475a-ae51-79bdc83c84d7",
   "metadata": {},
   "source": [
    "**Python built-in libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ec5462-905d-4b7c-b748-a43dbbe84b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, copy, random, json, time, datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab67a9a8-de37-4f03-9f10-700788527a63",
   "metadata": {},
   "source": [
    "**General helper libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c877637b-27c2-4d17-934d-a1e0c65422fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae5855-5a12-4098-9545-495fbc540506",
   "metadata": {},
   "source": [
    "**Libraries for interacting with the OpenAI API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d777fd-1191-4ce5-90e6-2660f36b5743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95257da-1df7-44de-8cc9-49071d6db842",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0ccdeb1-e3f2-4f96-b924-9a36287e78ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0b98b8-afcd-40b6-a2cb-173f95a14e98",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da331675-1d54-41a2-9c04-c77d331c3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function makes it easier to print rendered markdown through a code cell.\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def mprint(text, *args, **kwargs):\n",
    "    if 'end' in kwargs.keys():\n",
    "        text += kwargs['end']\n",
    "        \n",
    "    display(Markdown(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738dd1df-1de4-4a9c-a0d7-677aa0574439",
   "metadata": {},
   "source": [
    "### Set up huggingface\n",
    "\n",
    "In order to access the LlaMa2 models on Huggingface you need to request access and provide your hugginface hub token through your download requests.\n",
    "\n",
    "You can request access here:    \n",
    "https://huggingface.co/meta-llama/Llama-2-7b-hf\n",
    "\n",
    "You can find your hugginface hub token here:    \n",
    "https://huggingface.co/settings/tokens\n",
    "\n",
    "You can set it by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378edc4d-ec03-46bb-b8e8-e2b0bfb80ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your API key:  ········\n"
     ]
    }
   ],
   "source": [
    "if 'HUGGING_FACE_HUB_TOKEN' not in os.environ:\n",
    "    os.environ['HUGGING_FACE_HUB_TOKEN'] = getpass.getpass(prompt='Enter your API key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8534c0-8045-4f6c-a729-270c03b029a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "-----\n",
    "# Toy example\n",
    "----\n",
    "\n",
    "I will use a hypothetical dataset of earnings call sentences and try to identify sentences with a forward-looking statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23b59a4-422b-4b11-b060-3d19128d055d",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab2b4794-f171-472c-af50-8e8a75cbd0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path.cwd() / \"data\" / \"statements.json\", \"r\", encoding = \"utf-8\") as f:\n",
    "    statement_list = json.load(f)\n",
    "\n",
    "statement_df = pd.DataFrame(statement_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d180b8a-f283-435f-a792-ffa3a9551c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the last quarter, we managed to increase our revenue by 15% due to the successful launch of our new product line.\n"
     ]
    }
   ],
   "source": [
    "sentence_1 = statement_df.iloc[0].statement\n",
    "print(sentence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5b7e9ce-0634-421e-88dd-414f4e996194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We anticipate that our investments in R&D will lead to a 20% improvement in efficiency in the next two years.\n"
     ]
    }
   ],
   "source": [
    "sentence_2 = statement_df.iloc[1].statement\n",
    "print(sentence_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ad71a5-a9cf-41d7-a153-2ca3329d1be5",
   "metadata": {},
   "source": [
    "----\n",
    "## Prompt engineering\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25085321-639e-487e-a054-b15dba780fec",
   "metadata": {},
   "source": [
    "### Define prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb46bff4-53e9-41cc-9503-504b129202af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Task: classify whether the statement below contains a forward looking statements (fls).\n",
    "Rules:\n",
    "- Answer using JSON in the following format: {{\"contains_fls\" : 0 or 1}}\n",
    "Statement:\n",
    "> {statement}\n",
    "JSON =\n",
    "\"\"\".strip()\n",
    "\n",
    "## Note, the curly braces are what we will fill in for each observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2c0c6-35f0-4dda-89fc-c9cd129f21e5",
   "metadata": {},
   "source": [
    "### Create prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1aa5441-0acf-4206-88d5-41e33755440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "id_list = []\n",
    "for i, row in statement_df.iterrows():\n",
    "    prompt = prompt_template.format(**{\n",
    "        \"statement\" : row[\"statement\"]\n",
    "    })\n",
    "    prompt_list.append(prompt)\n",
    "    id_list.append(row[\"i\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85e928df-a102-4343-9a18-1e54591eec0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: classify whether the statement below contains a forward looking statements (fls).\n",
      "Rules:\n",
      "- Answer using JSON in the following format: {\"contains_fls\" : 0 or 1}\n",
      "Statement:\n",
      "> In the last quarter, we managed to increase our revenue by 15% due to the successful launch of our new product line.\n",
      "JSON =\n"
     ]
    }
   ],
   "source": [
    "print(prompt_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4650e1ab-d2eb-4346-878c-eed2ad12db1f",
   "metadata": {},
   "source": [
    "----\n",
    "# Run zero-shot inference\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1272b16b-3616-45da-9558-c5ec058abf01",
   "metadata": {},
   "source": [
    "#### Set up parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb570b0a-176d-4fe9-a97e-0820553fc32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(\n",
    "    max_tokens=100,\n",
    "    temperature=0,\n",
    "    stop = \"\"\"\n",
    "}\n",
    "\n",
    "JSON =     \n",
    "\"\"\".strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a84b8f-869f-497c-911b-d2f3b34e9857",
   "metadata": {},
   "source": [
    "#### Adapt prompts to fit llama2 instruct style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acc93a57-1471-46c8-8ece-c872cee58328",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_format = \"\"\"<s>[INST] <<SYS>>\n",
    "{system_prompt}\n",
    "<</SYS>>\n",
    "\n",
    "{user_message} [/INST]\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60b4c9ef-3d8f-4f71-ac24-5afcdf26967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant who only returns valid JSON.\"\n",
    "llama_prompts = []\n",
    "for prompt in prompt_list:\n",
    "    llama_prompts.append(\n",
    "        chat_format.format(system_prompt = system_message, user_message = prompt)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96223c08-5337-4ee4-b21c-868b4ac46cf0",
   "metadata": {},
   "source": [
    "#### Initialize llama2 7b model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1707e357-c2e6-498a-ae62-ace8419a5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "model_label = model.split(\"/\")[-1].replace(\"-\", \"_\")\n",
    "model_pred_loc = Path.cwd() / \"data\" / f\"{model_label}_{int(time.time())}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec6890fd-3cf2-4178-a728-96678d1b2e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-05 04:06:17 llm_engine.py:72] Initializing an LLM engine with config: model='meta-llama/Llama-2-7b-chat-hf', tokenizer='meta-llama/Llama-2-7b-chat-hf', tokenizer_mode=auto, revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\n",
      "INFO 10-05 04:06:17 tokenizer.py:30] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n",
      "INFO 10-05 04:06:22 llm_engine.py:205] # GPU blocks: 1050, # CPU blocks: 512\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=model, max_num_batched_tokens=4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a7978-35f7-4507-b5ea-c64c72e1d8c9",
   "metadata": {},
   "source": [
    "#### Generate inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14f4f24a-ffa0-4d49-a9fd-5de72503d732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 64.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 943 ms, sys: 1.11 ms, total: 944 ms\n",
      "Wall time: 941 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "llama2_7b_ouputs = llm.generate(llama_prompts, sampling_params=sampling_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2c1bd1-d2e9-4518-ad22-8a1962061619",
   "metadata": {},
   "source": [
    "#### Process predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d12d12a-4eac-47fd-b877-548ede880980",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i, item in enumerate(llama2_7b_ouputs):\n",
    "    full_item = copy.deepcopy(item.__dict__)\n",
    "    full_item[\"completion_obj\"] = full_item[\"outputs\"][0].__dict__\n",
    "    del full_item[\"outputs\"]\n",
    "    preds.append({\n",
    "        \"i\" : id_list[i],\n",
    "        \"completion\" : item.outputs[0].text,\n",
    "        \"raw_obj\" : full_item\n",
    "    })\n",
    "\n",
    "with open(model_pred_loc, \"w\", encoding = \"utf-8\") as f:\n",
    "    json.dump(preds, f)\n",
    "    \n",
    "llama2_7b_preds = copy.deepcopy(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ce427-e82c-49cd-b64b-8a01797aa9fb",
   "metadata": {},
   "source": [
    "### Evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1fd916-47f5-4cc9-900e-42eb61e48c01",
   "metadata": {},
   "source": [
    "#### Process into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "089613ac-173d-42c2-af00-c311fea7e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = []\n",
    "for item in llama2_7b_preds:\n",
    "    result = json.loads(item[\"completion\"])\n",
    "    res_list.append({\n",
    "        \"i\" : item[\"i\"],\n",
    "        \"fls_prediction\" : result[\"contains_fls\"]\n",
    "    })\n",
    "    \n",
    "res_df = pd.DataFrame(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "873e3d20-98e9-4783-8f61-125d0edf0588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    51\n",
       "0     9\n",
       "Name: fls_prediction, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.fls_prediction.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d7d121-8bc2-4dc1-a310-1eed7973cf89",
   "metadata": {},
   "source": [
    "#### Show confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e581bd36-b230-416e-9bba-e8db2064dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a84325c-eacd-44a8-a416-b45078febabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df = pd.merge(statement_df, res_df, on = \"i\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc4afaa0-8a53-4c5a-835c-a9a2820d9496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.27      0.41        30\n",
      "           1       0.57      0.97      0.72        30\n",
      "\n",
      "    accuracy                           0.62        60\n",
      "   macro avg       0.73      0.62      0.56        60\n",
      "weighted avg       0.73      0.62      0.56        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "    combo_df[\"contains_fls\"], \n",
    "    combo_df[\"fls_prediction\"]\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
